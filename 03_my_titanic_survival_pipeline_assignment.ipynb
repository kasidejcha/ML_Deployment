{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abZkb-84gSn6"
      },
      "source": [
        "## Predicting Survival on the Titanic\n",
        "\n",
        "### History\n",
        "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
        "\n",
        "### Assignment:\n",
        "\n",
        "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
        "\n",
        "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yyz9DtVglfC7",
        "outputId": "1b23ef02-734f-4704-90d8-89638739a056"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.1.2-py2.py3-none-any.whl (180 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 180 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.0.1)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.19.5)\n",
            "Collecting statsmodels>=0.11.1\n",
            "  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from feature_engine) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature_engine) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.3->feature_engine) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->feature_engine) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->feature_engine) (3.0.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
            "Installing collected packages: statsmodels, feature-engine\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed feature-engine-1.1.2 statsmodels-0.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_elmXl9WgSn_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# to handle datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# to divide train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# feature scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# to build the models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# to evaluate the models\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# to persist the model and the scaler\n",
        "import joblib\n",
        "\n",
        "# ========== NEW IMPORTS ========\n",
        "# Respect to notebook 02-Predicting-Survival-Titanic-Solution\n",
        "\n",
        "# pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "# for the preprocessors\n",
        "from feature_engine.imputation import (\n",
        "    AddMissingIndicator,\n",
        "    MeanMedianImputer,\n",
        "    CategoricalImputer,\n",
        ")\n",
        "\n",
        "# for encoding categorical variables\n",
        "from feature_engine.encoding import (\n",
        "    RareLabelEncoder,\n",
        "    OrdinalEncoder,\n",
        "    OneHotEncoder,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWZmlzeOgSoX"
      },
      "source": [
        "## Prepare the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M5azaiPmgSoX",
        "outputId": "93a8097f-b389-4e2f-e788-89ef301fdf57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>ticket</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>home.dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allen, Miss. Elisabeth Walton</td>\n",
              "      <td>female</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24160</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>B5</td>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>?</td>\n",
              "      <td>St Louis, MO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.55</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>11</td>\n",
              "      <td>?</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Miss. Helen Loraine</td>\n",
              "      <td>female</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.55</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
              "      <td>male</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.55</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>?</td>\n",
              "      <td>135</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
              "      <td>female</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.55</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  survived  ... body                        home.dest\n",
              "0       1         1  ...    ?                     St Louis, MO\n",
              "1       1         1  ...    ?  Montreal, PQ / Chesterville, ON\n",
              "2       1         0  ...    ?  Montreal, PQ / Chesterville, ON\n",
              "3       1         0  ...  135  Montreal, PQ / Chesterville, ON\n",
              "4       1         0  ...    ?  Montreal, PQ / Chesterville, ON\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# load the data - it is available open source and online\n",
        "\n",
        "data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl')\n",
        "\n",
        "# display data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zxI69jPdgSoZ"
      },
      "outputs": [],
      "source": [
        "# replace interrogation marks by NaN values\n",
        "\n",
        "data = data.replace('?', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e04nCRZLgSoa"
      },
      "outputs": [],
      "source": [
        "# retain only the first cabin if more than\n",
        "# 1 are available per passenger\n",
        "\n",
        "def get_first_cabin(row):\n",
        "    try:\n",
        "        return row.split()[0]\n",
        "    except:\n",
        "        return np.nan\n",
        "    \n",
        "data['cabin'] = data['cabin'].apply(get_first_cabin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "61P-1jEIgSoa"
      },
      "outputs": [],
      "source": [
        "# extracts the title (Mr, Ms, etc) from the name variable\n",
        "\n",
        "def get_title(passenger):\n",
        "    line = passenger\n",
        "    if re.search('Mrs', line):\n",
        "        return 'Mrs'\n",
        "    elif re.search('Mr', line):\n",
        "        return 'Mr'\n",
        "    elif re.search('Miss', line):\n",
        "        return 'Miss'\n",
        "    elif re.search('Master', line):\n",
        "        return 'Master'\n",
        "    else:\n",
        "        return 'Other'\n",
        "    \n",
        "data['title'] = data['name'].apply(get_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "whtvv7UsgSob"
      },
      "outputs": [],
      "source": [
        "# cast numerical variables as floats\n",
        "\n",
        "data['fare'] = data['fare'].astype('float')\n",
        "data['age'] = data['age'].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qygo1wtSgSoc",
        "outputId": "55d90454-f725-4785-dbd5-a3c0768cd415"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>B5</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22</td>\n",
              "      <td>S</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22</td>\n",
              "      <td>S</td>\n",
              "      <td>Miss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22</td>\n",
              "      <td>S</td>\n",
              "      <td>Mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22</td>\n",
              "      <td>S</td>\n",
              "      <td>Mrs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  survived     sex      age  ...      fare  cabin  embarked   title\n",
              "0       1         1  female  29.0000  ...  211.3375     B5         S    Miss\n",
              "1       1         1    male   0.9167  ...  151.5500    C22         S  Master\n",
              "2       1         0  female   2.0000  ...  151.5500    C22         S    Miss\n",
              "3       1         0    male  30.0000  ...  151.5500    C22         S      Mr\n",
              "4       1         0  female  25.0000  ...  151.5500    C22         S     Mrs\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# drop unnecessary variables\n",
        "\n",
        "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
        "\n",
        "# display data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubUa-QT1gSod"
      },
      "outputs": [],
      "source": [
        "# # save the data set\n",
        "\n",
        "# data.to_csv('titanic.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV_RcAWpgSod"
      },
      "source": [
        "# Begin Assignment\n",
        "\n",
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LIZXdQ4OgSod"
      },
      "outputs": [],
      "source": [
        "# list of variables to be used in the pipeline's transformers\n",
        "\n",
        "NUMERICAL_VARIABLES = ['fare', 'age']\n",
        "\n",
        "CATEGORICAL_VARIABLES = ['sex', 'embarked', 'title', 'cabin']\n",
        "\n",
        "CABIN = ['cabin']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS0WP5_ogSoe"
      },
      "source": [
        "## Separate data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ykys5dogSoe",
        "outputId": "95ddeefb-f86e-4f94-b087-4868149528e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1047, 9), (262, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.drop('survived', axis=1),  # predictors\n",
        "    data['survived'],  # target\n",
        "    test_size=0.2,  # percentage of obs in test set\n",
        "    random_state=0)  # seed to ensure reproducibility\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cabin'].str[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOodmRVUiht9",
        "outputId": "2dc3fa7c-e51d-4225-fec0-2db2fd2bb7aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         B\n",
              "1         C\n",
              "2         C\n",
              "3         C\n",
              "4         C\n",
              "       ... \n",
              "1304    NaN\n",
              "1305    NaN\n",
              "1306    NaN\n",
              "1307    NaN\n",
              "1308    NaN\n",
              "Name: cabin, Length: 1309, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ictV8ygSoe"
      },
      "source": [
        "## Preprocessors\n",
        "\n",
        "### Class to extract the letter from the variable Cabin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A9eYF_kbgSof"
      },
      "outputs": [],
      "source": [
        "class ExtractLetterTransformer(BaseEstimator, TransformerMixin):\n",
        "    # Extract fist letter of variable\n",
        "\n",
        "    def __init__(self, variables):\n",
        "\n",
        "        if not isinstance(variables, list):\n",
        "          raise ValueError('variables should be a list')\n",
        "        \n",
        "        self.variables = variables\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "      return self\n",
        "        \n",
        "\n",
        "    def transform(self, X):\n",
        "      X = X.copy()\n",
        "      for feature in self.variables:\n",
        "        X[feature] = X[feature].str[0]\n",
        "\n",
        "      return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swvBbTNCgSof"
      },
      "source": [
        "## Pipeline\n",
        "\n",
        "- Impute categorical variables with string missing\n",
        "- Add a binary missing indicator to numerical variables with missing data\n",
        "- Fill NA in original numerical variable with the median\n",
        "- Extract first letter from cabin\n",
        "- Group rare Categories\n",
        "- Perform One hot encoding\n",
        "- Scale features with standard scaler\n",
        "- Fit a Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rZRhdr--gSof"
      },
      "outputs": [],
      "source": [
        "# set up the pipeline\n",
        "titanic_pipe = Pipeline([\n",
        "\n",
        "    # ===== IMPUTATION =====\n",
        "    # impute categorical variables with string 'missing'\n",
        "    ('categorical_imputation', CategoricalImputer(imputation_method='missing',\n",
        "                                                     variables = CATEGORICAL_VARIABLES)),\n",
        "\n",
        "    # add missing indicator to numerical variables\n",
        "    ('missing_indicator', AddMissingIndicator(variables = NUMERICAL_VARIABLES)),\n",
        "\n",
        "    # impute numerical variables with the median\n",
        "    ('median_imputation', MeanMedianImputer(imputation_method = 'median',\n",
        "                                            variables = NUMERICAL_VARIABLES)),\n",
        "\n",
        "\n",
        "    # Extract first letter from cabin\n",
        "    ('extract_letter', ExtractLetterTransformer(variables = CABIN)),\n",
        "\n",
        "\n",
        "    # == CATEGORICAL ENCODING ======\n",
        "    # remove categories present in less than 5% of the observations (0.05)\n",
        "    # group them in one category called 'Rare'\n",
        "    ('rare_label_encoder', RareLabelEncoder(tol=0.01, \n",
        "                                            n_categories=1, \n",
        "                                            variables=CATEGORICAL_VARIABLES)),\n",
        "\n",
        "\n",
        "    # encode categorical variables using one hot encoding into k-1 variables\n",
        "    ('categorical_encoder', OneHotEncoder(drop_last=True,\n",
        "                                          variables = CATEGORICAL_VARIABLES)),\n",
        "\n",
        "    # scale using standardization\n",
        "    ('scaler', StandardScaler()),\n",
        "\n",
        "    # logistic regression (use C=0.0005 and random_state=0)\n",
        "    ('Logit', LogisticRegression(C=0.0005, random_state=0)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7dpjPrWgSog",
        "outputId": "50f48151-2df6-48c3-a4af-ada70431ba9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('categorical_imputation',\n",
              "                 CategoricalImputer(variables=['sex', 'embarked', 'title',\n",
              "                                               'cabin'])),\n",
              "                ('missing_indicator',\n",
              "                 AddMissingIndicator(variables=['fare', 'age'])),\n",
              "                ('median_imputation',\n",
              "                 MeanMedianImputer(variables=['fare', 'age'])),\n",
              "                ('extract_letter',\n",
              "                 ExtractLetterTransformer(variables=['cabin'])),\n",
              "                ('rare_label_encoder',\n",
              "                 RareLabelEncoder(n_categories=1, tol=0.01,\n",
              "                                  variables=['sex', 'embarked', 'title',\n",
              "                                             'cabin'])),\n",
              "                ('categorical_encoder',\n",
              "                 OneHotEncoder(drop_last=True,\n",
              "                               variables=['sex', 'embarked', 'title',\n",
              "                                          'cabin'])),\n",
              "                ('scaler', StandardScaler()),\n",
              "                ('Logit', LogisticRegression(C=0.0005, random_state=0))])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# train the pipeline\n",
        "titanic_pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMAdDnqUgSog"
      },
      "source": [
        "## Make predictions and evaluate model performance\n",
        "\n",
        "Determine:\n",
        "- roc-auc\n",
        "- accuracy\n",
        "\n",
        "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8ezDOcOgSog",
        "outputId": "4c9fd8cc-4b67-414b-aadd-2ee3df9c8f6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train roc-auc: 0.84411514683153\n",
            "train accuracy: 0.723018147086915\n",
            "\n",
            "test roc-auc: 0.8360802469135802\n",
            "test accuracy: 0.7061068702290076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# make predictions for train set\n",
        "class_ = titanic_pipe.predict(X_train)\n",
        "pred = titanic_pipe.predict_proba(X_train)[:,1]\n",
        "\n",
        "# determine mse and rmse\n",
        "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
        "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
        "print()\n",
        "\n",
        "# make predictions for test set\n",
        "class_ = titanic_pipe.predict(X_test)\n",
        "pred = titanic_pipe.predict_proba(X_test)[:,1]\n",
        "\n",
        "# determine mse and rmse\n",
        "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
        "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VhB1yRBgSoh"
      },
      "source": [
        "That's it! Well done\n",
        "\n",
        "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "feml",
      "language": "python",
      "name": "feml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "03-titanic-survival-pipeline-assignment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}